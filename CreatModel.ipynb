{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import geometry_utils\n",
    "import hypercolumn\n",
    "import sys\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from joblib import dump, load\n",
    "import io\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import scipy.misc\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "from numpy.random import random as rnd\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from PIL import Image\n",
    "from poisson_disk import PoissonDiskSampler\n",
    "import skimage.morphology\n",
    "import skimage.measure\n",
    "import scipy.stats\n",
    "import dataset_utils\n",
    "import joblib\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "def main():\n",
    "    cub = dataset_utils.CUB_200_2011(settings.CUB_FOLDER_PATH)\n",
    "    imgs_addr = cub.image_addrs()\n",
    "    trimaps_addr = cub.trimap_addrs()\n",
    "    imgs_anno = dataset_utils.BerkeleyAnnotaionHelper(cub)\n",
    "    IDtrain, IDtest = cub.train_test_id()\n",
    "    \n",
    "    dh = hypercolumn.hypercolumn()\n",
    "    \n",
    "    part_name= 'head'\n",
    "    \n",
    "    pos_x = []\n",
    "    neg_x = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    index=0\n",
    "    start = dt.now()\n",
    "    \n",
    "    d=0\n",
    "    for i, img_id in enumerate(IDtrain):\n",
    "        \n",
    "        index +=1\n",
    "        print (\"done\" ,index, \"in\", (dt.now() - start))\n",
    "        img = cv2.imread(imgs_addr[img_id])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        img_gray = cv2.imread(trimaps_addr[img_id], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        height,width,domain = img.shape\n",
    "        print(imgs_addr[img_id])\n",
    "        \n",
    "        part_box = imgs_anno.annotation(img_id, part_name)\n",
    "        if not part_box.is_valid():\n",
    "            continue\n",
    "        pos, neg = dh.image_point_features(img,img_gray, part_box, part_name)\n",
    "         \n",
    "        pos_x.append(pos)\n",
    "        neg_x.append(neg)\n",
    "        \n",
    "        \n",
    "    pos_x = np.vstack(pos_x)\n",
    "    neg_x = np.vstack(neg_x)\n",
    "    \n",
    "    pos_y = np.ones(np.array(pos_x).shape[0], dtype=np.int)\n",
    "    \n",
    "    neg_y = np.zeros(np.array(neg_x).shape[0], dtype=np.int)\n",
    "    \n",
    "    X = np.vstack((pos_x, neg_x))\n",
    "    y = np.concatenate((pos_y, neg_y))\n",
    "    \n",
    "    print ('started learning')\n",
    "    l_start = dt.now() \n",
    "    #100\n",
    "    model = sklearn.ensemble.RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=1, random_state=None)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    preds = model.predict_proba(X)\n",
    "    print (sklearn.metrics.auc(y, preds[:, 0]))\n",
    "    \n",
    "    joblib.dump(model, '%s_model(Vgg19-tree100).mdl' % part_name, compress=3)\n",
    "    \n",
    "    #150\n",
    "    model = sklearn.ensemble.RandomForestClassifier(n_estimators=150, max_depth=20, n_jobs=1, random_state=None)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    preds = model.predict_proba(X)\n",
    "    print (sklearn.metrics.auc(y, preds[:, 0]))\n",
    "    \n",
    "    joblib.dump(model, '%s_model(Vgg19-tree150).mdl' % part_name, compress=3)\n",
    "    \n",
    "    #200\n",
    "    model = sklearn.ensemble.RandomForestClassifier(n_estimators=200, max_depth=20, n_jobs=1, random_state=None)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    preds = model.predict_proba(X)\n",
    "    print (sklearn.metrics.auc(y, preds[:, 0]))\n",
    "    \n",
    "    joblib.dump(model, '%s_model(Vgg19-tree200).mdl' % part_name, compress=3)\n",
    "    \n",
    "    print ('learned in', (dt.now() - l_start))\n",
    "    print ('finsihed in', (dt.now() - start))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
